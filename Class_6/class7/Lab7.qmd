---
title: "class7"
format: pdf
---


```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
```


>**Q1**. How many rows and columns are in your new data frame named xerox ? What R functions could you use to answer this questions?

```{r}
dim(x)
```

There are 17 rows and 5 columns

Checking Data via *view*

```{r}
#View(x)
##Row names are part of first column. 

rownames(x) <- x[,1]
x <- x[,-1]
head(x)

dim(x)

#another way of argueing row
x <- read.csv(url, row.names=1)
```

>**Q2.** Which approach to solving the \'row-names problem\' mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

I prefer using the read.csv function to change row names since it's more concise and it gets the problem out of the way sooner. It also changes the data table that is uploaded into your program.

Lets cluster into 3 groups or same `x` data and make a plot

```{r}
km <- kmeans(x, enters=4)
plot(x, col=km$cluster)

#tot ss value tells closseness of points?? idk. cluster size or something. value that has biggest difference is best one (elbow point). Scree plots? 
```

Barplot vs pairwise barplot

```{r}
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))

barplot(as.matrix(x), beside=F, col=rainbow(nrow(x)))


```

**>Q3**: Changing what optional argument in the above **barplot()** function results in the following plot?

setting beside argeument to beside=F

>**Q5**: Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

```{r}
pairs(x, col=rainbow(10), pch=16)
#each column
```

Comparing data from tw countries in data set via x and y axis. If point is on exact diagonal, it is equal for both countries. If it's above or under the diagonal it (food category) is more for which ever country it's correlated to. If most points are making a diagonal, then the countries are pretty similar. If the points are away from diagonal, there are more differences between the two countries.

**>Q6**. What is the main differences between N. Ireland and the other countries of the UK in terms of this data-set?

The blue point?

## Using PCA

The main PCA function in base R is called `prcomp()` . It expects the transpose, t() ,of our data

```{r}
# Use the prcomp() PCA function 
pca <- prcomp( t(x) )
summary(pca)
#tells proportion of variance (how much spread)
#can capture 96.5% of data using two new axis'?
```

```{r}
attributes(pca)
#
```

**>Q7**. Complete the code below to generate a plot of PC1 vs PC2. The second line adds text labels over the data points.

```{r}
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(x))
```

>**Q8.** Customize your plot so that the colors of the country names match the colors in our UK and Ireland map and table at start of this document.

```{r}
plot(pca$x[,1], pca$x[,2], col="transparent")
text(pca$x[,1], pca$x[,2], colnames(x), col=c("orange", "red", "blue", "darkgreen"), pch=16)
```

# Class 7

We can use the `rnorm()` function to get random numbers from a normal distribution around a given mean.

```{r}
hist(rnorm(5000, mean=1))
```

```         
Let's get 30 points with a mean of 3.
```

```{r}
rnorm1 <- rnorm(30, mean=3)
rnorm1
```

```{r}
tmp <- c(rnorm(30, mean=3), rnorm(30, mean=-3))
tmp
```

```{r}
# Put these two together
x <- cbind(x=tmp, y=rev(tmp))
x
plot(x)
```

## K-means Clustering 

Very popular clustering method for big data sets.

```{r}
km <- kmeans(x, 2)
km
```

```{r}
km$cluster
```

\>Q: How many points are in each cluster?

```{r}
# We can use km$size to see how many points are in each cluster
# In this case, there are 30 points in each cluster
km$size
```

\>Q: What 'component' of your result object details:
cluster size?

cluster assignment/membership?

cluster center?

```         

```

```{r}
# Cluster size
km$size

# Membership
km$cluster

# Cluster center
km$centers
```

\>Q: Plot x colored by the kmeans cluster assignment and add cluster centers as blue points.

```{r}
mycols <- km$cluster
mycols <- mycols + 1
plot(x, col = mycols)
points(km$centers, col = 'blue', pch = 15, cex = 3)
```

\>Q: Let's cluster into 3 groups or same 'x' data and make a plot.

```{r}
km2 <- kmeans(x, 3)
km2

plot(x, col = km2$cluster)
points(km2$centers, col = 'blue', pch = 15, cex = 3)
```

## Hierarchical Clustering

We can use the `hclust()` function for Hierarchical Clustering. Unlike `kmeans()`, where we could just pass in our data as input, we need to give `hclust()` a "distance matrix".

We will use `dist()` function to start with.

```{r}
d <- dist(x)
# will give you a distance matrix
hc <- hclust(d)
hc

```

```{r}
plot(hc)
```

------------------------------------------------------------------------

------------------------------------------------------------------------

\*I can now cut my tree with the cuttree() to yeil a cluster membership vectore

```{r}
grps <- cuttree(hc, h=8)
grps
```

you can also

```{r}
plot(x, col=grps)
```
